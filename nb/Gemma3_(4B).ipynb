{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geeteshkamble/AI/blob/main/nb/Gemma3_(4B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from unsloth import FastModel\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from unsloth.chat_templates import get_chat_template, standardize_data_formats, train_on_responses_only\n",
        "from transformers import TextStreamer\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import requests"
      ],
      "metadata": {
        "id": "nVpJtnXzXERU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Available models for training\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "]"
      ],
      "metadata": {
        "id": "lzNXFj_CXGSb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_colab():\n",
        "    \"\"\"Setup Colab environment with required dependencies.\"\"\"\n",
        "    if \"COLAB_\" in \"\".join(os.environ.keys()):\n",
        "        print(\"Setting up Colab environment...\")\n",
        "        # Install dependencies\n",
        "        !pip install --no-deps unsloth vllm\n",
        "        !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "        !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "        # Handle vLLM requirements\n",
        "        f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "        with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "            file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "        !pip install -r vllm_requirements.txt\n",
        "\n",
        "        # Clear some modules to avoid conflicts\n",
        "        modules = list(sys.modules.keys())\n",
        "        for x in modules:\n",
        "            if \"PIL\" in x or \"google\" in x:\n",
        "                sys.modules.pop(x)\n",
        "\n",
        "        print(\"Colab environment setup complete!\")"
      ],
      "metadata": {
        "id": "RBak07mAXWt5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_dataset(csv_path):\n",
        "    \"\"\"Load and prepare the negative words dataset.\"\"\"\n",
        "    try:\n",
        "        # Read the CSV file with explicit column names\n",
        "        df = pd.read_csv(csv_path, encoding='utf-8', names=['Child', 'Robot'])\n",
        "\n",
        "        # Print first few rows for debugging\n",
        "        print(\"\\nFirst few rows of the dataset:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Create conversations format\n",
        "        conversations = []\n",
        "        for _, row in df.iterrows():\n",
        "            # Skip empty rows or header row\n",
        "            if pd.isna(row['Child']) or pd.isna(row['Robot']) or row['Child'] == 'Child':\n",
        "                continue\n",
        "\n",
        "            # Clean and validate the text\n",
        "            child_text = str(row['Child']).strip()\n",
        "            robot_text = str(row['Robot']).strip()\n",
        "\n",
        "            if child_text and robot_text:  # Only add if both texts are non-empty\n",
        "                conversation = [\n",
        "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": child_text}]},\n",
        "                    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": robot_text}]}\n",
        "                ]\n",
        "                conversations.append({\"conversations\": conversation})\n",
        "\n",
        "        if not conversations:\n",
        "            raise ValueError(\"No valid conversations found in the dataset\")\n",
        "\n",
        "        # Convert to HuggingFace dataset\n",
        "        dataset = Dataset.from_list(conversations)\n",
        "        print(f\"\\nSuccessfully created {len(conversations)} conversation pairs\")\n",
        "        return dataset\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"Error: The CSV file is empty\")\n",
        "        raise\n",
        "    except pd.errors.ParserError:\n",
        "        print(\"Error: The CSV file is not properly formatted\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {str(e)}\")\n",
        "        print(\"\\nPlease ensure your CSV file:\")\n",
        "        print(\"1. Has two columns (negative statement and positive response)\")\n",
        "        print(\"2. Is properly formatted with commas as separators\")\n",
        "        print(\"3. Contains valid text in both columns\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "APB-nfdzXYuY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(dataset, tokenizer):\n",
        "    \"\"\"Format the dataset using the chat template.\"\"\"\n",
        "    def formatting_prompts_func(examples):\n",
        "        convos = examples[\"conversations\"]\n",
        "        texts = []\n",
        "        for convo in convos:\n",
        "            # Format each conversation into a single text string\n",
        "            formatted_text = \"\"\n",
        "            for message in convo:\n",
        "                role = message[\"role\"]\n",
        "                content = message[\"content\"][0][\"text\"]\n",
        "                if role == \"user\":\n",
        "                    formatted_text += f\"<start_of_turn>user\\n{content}<end_of_turn>\\n\"\n",
        "                else:  # assistant\n",
        "                    formatted_text += f\"<start_of_turn>model\\n{content}<end_of_turn>\\n\"\n",
        "            texts.append(formatted_text)\n",
        "        return {\"text\": texts}\n",
        "\n",
        "    return dataset.map(formatting_prompts_func, batched=True)"
      ],
      "metadata": {
        "id": "OA6rIuKOXbgg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataset, model_name=\"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\", max_steps=60):\n",
        "    \"\"\"Train the Gemma-3 model on the dataset.\"\"\"\n",
        "    # Initialize model and tokenizer\n",
        "    model, tokenizer = FastModel.from_pretrained(\n",
        "        model_name=model_name,\n",
        "        max_seq_length=2048,  # Choose any for long context!\n",
        "        load_in_4bit=True,    # 4 bit quantization to reduce memory\n",
        "        load_in_8bit=False,   # A bit more accurate, uses 2x memory\n",
        "        full_finetuning=False, # We have full finetuning now!\n",
        "    )\n",
        "\n",
        "    # Get PEFT model\n",
        "    model = FastModel.get_peft_model(\n",
        "        model,\n",
        "        finetune_vision_layers=False,  # Turn off for just text!\n",
        "        finetune_language_layers=True,  # Should leave on!\n",
        "        finetune_attention_modules=True,  # Attention good for GRPO\n",
        "        finetune_mlp_modules=True,  # Should leave on always!\n",
        "        r=8,           # Larger = higher accuracy, but might overfit\n",
        "        lora_alpha=8,  # Recommended alpha == r at least\n",
        "        lora_dropout=0,\n",
        "        bias=\"none\",\n",
        "        random_state=3407,\n",
        "    )\n",
        "\n",
        "    # Format dataset\n",
        "    print(\"\\nFormatting dataset for training...\")\n",
        "    dataset = format_dataset(dataset, tokenizer)\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=dataset,\n",
        "        eval_dataset=None,\n",
        "        args=SFTConfig(\n",
        "            dataset_text_field=\"text\",\n",
        "            per_device_train_batch_size=2,\n",
        "            gradient_accumulation_steps=4,  # Use GA to mimic batch size!\n",
        "            warmup_steps=5,\n",
        "            max_steps=max_steps,\n",
        "            learning_rate=2e-4,  # Reduce to 2e-5 for long training runs\n",
        "            logging_steps=1,\n",
        "            optim=\"adamw_8bit\",\n",
        "            weight_decay=0.01,\n",
        "            lr_scheduler_type=\"linear\",\n",
        "            seed=3407,\n",
        "            report_to=\"none\",  # Use this for WandB etc\n",
        "            dataset_num_proc=2,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nStarting training...\")\n",
        "    trainer_stats = trainer.train()\n",
        "\n",
        "    return model, tokenizer, trainer_stats\n"
      ],
      "metadata": {
        "id": "9G4cFLF_Xdly"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results_to_csv(results, filename=None):\n",
        "    \"\"\"Save test results to a CSV file.\"\"\"\n",
        "    from datetime import datetime  # Move the import here\n",
        "\n",
        "    if filename is None:\n",
        "        # Create a filename with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"test_results_{timestamp}.csv\"\n",
        "\n",
        "    # Prepare data for CSV\n",
        "    data = []\n",
        "    for result in results:\n",
        "        data.append({\n",
        "            'test_case': result['input'],\n",
        "            'model_response': result['response'],\n",
        "            'response_type': result['response_type']\n",
        "        })\n",
        "\n",
        "    # Convert to DataFrame and save to CSV\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"\\nTest results saved to {filename}\")\n",
        "    return filename"
      ],
      "metadata": {
        "id": "6tQYbNR1G8SE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, tokenizer, test_inputs):\n",
        "    \"\"\"Test the trained model with sample inputs and classify response types.\"\"\"\n",
        "    results = []\n",
        "    for input_text in test_inputs:\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": input_text}]\n",
        "        }]\n",
        "\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "        )\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **tokenizer([text], return_tensors=\"pt\").to(\"cuda\"),\n",
        "            max_new_tokens=200,\n",
        "            temperature=1.0,\n",
        "            top_p=0.95,\n",
        "            top_k=64,\n",
        "        )\n",
        "\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "        # Simple response type classification\n",
        "        response_type = \"positive\"  # default\n",
        "        negative_words = [\"no\", \"not\", \"never\", \"can't\", \"cannot\", \"don't\", \"doesn't\"]\n",
        "        if any(word in response.lower() for word in negative_words):\n",
        "            response_type = \"negative\"\n",
        "\n",
        "        results.append({\n",
        "            \"input\": input_text,\n",
        "            \"response\": response,\n",
        "            \"response_type\": response_type\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "BioIU0SFXpcJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Setup Colab environment if running in Colab\n",
        "    setup_colab()\n",
        "\n",
        "    # Load and prepare dataset\n",
        "    print(\"Loading and preparing dataset...\")\n",
        "    try:\n",
        "        dataset = load_and_prepare_dataset(\"Negative words.csv\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFailed to load dataset: {str(e)}\")\n",
        "        print(\"\\nPlease check your CSV file and try again.\")\n",
        "        return\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nStarting model training...\")\n",
        "    try:\n",
        "        model, tokenizer, trainer_stats = train_model(dataset)\n",
        "        print(f\"\\nTraining completed in {trainer_stats.metrics['train_runtime']} seconds\")\n",
        "        print(f\"Training completed in {round(trainer_stats.metrics['train_runtime']/60, 2)} minutes\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during training: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Show memory stats\n",
        "    try:\n",
        "        gpu_stats = torch.cuda.get_device_properties(0)\n",
        "        used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "        max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "        print(f\"\\nGPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "        print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "        print(f\"Peak reserved memory % of max memory = {round(used_memory / max_memory * 100, 3)} %.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError getting GPU stats: {str(e)}\")\n",
        "\n",
        "    # Save the model\n",
        "    print(\"\\nSaving model...\")\n",
        "    try:\n",
        "        model.save_pretrained(\"gemma-3-negative-words\")\n",
        "        tokenizer.save_pretrained(\"gemma-3-negative-words\")\n",
        "        print(\"Model saved successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError saving model: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Test cases\n",
        "    test_inputs = [\n",
        "          \"Why can't I eat ice cream for breakfast every day?\",\n",
        "          \"Isn't it okay not to clean my room if I like the mess?\",\n",
        "          \"Why don't socks ever stay together?\",\n",
        "          \"Can I never go to school again and become a superhero instead?\",\n",
        "          \"Why is broccoli not candy if it looks like tiny trees?\",\n",
        "          \"Can I not do my homework if my dog sat on it?\",\n",
        "          \"Why can't I stay up forever and be a night owl?\",\n",
        "          \"Is it okay not to share my toys if I really, really love them?\",\n",
        "          \"Can I not take a bath if I didn't get dirty playing video games?\",\n",
        "          \"Why doesn't my cereal stay crunchy forever?\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTesting model with sample inputs:\")\n",
        "    try:\n",
        "        results = test_model(model, tokenizer, test_inputs)\n",
        "\n",
        "        # Save results to CSV\n",
        "        results_file = save_results_to_csv(results)\n",
        "        print(f\"\\nResults have been saved to {results_file}\")\n",
        "\n",
        "        # Display results in console\n",
        "        for result in results:\n",
        "            print(f\"\\nInput: {result['input']}\")\n",
        "            print(f\"Response: {result['response']}\")\n",
        "            print(f\"Response Type: {result['response_type']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during testing: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # # Save to float16 for deployment\n",
        "    # print(\"\\nSaving model in float16 format for deployment...\")\n",
        "    # try:\n",
        "    #     model.save_pretrained_merged(\"gemma-3-negative-words-float16\", tokenizer)\n",
        "    #     print(\"Float16 model saved successfully\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nError saving float16 model: {str(e)}\")\n",
        "\n",
        "    # # Save to GGUF format\n",
        "    # print(\"\\nSaving model in GGUF format...\")\n",
        "    # try:\n",
        "    #     model.save_pretrained_gguf(\n",
        "    #         \"gemma-3-negative-words-gguf\",\n",
        "    #         quantization_type=\"Q8_0\",  # For now only Q8_0, BF16, F16 supported\n",
        "    #     )\n",
        "    #     print(\"GGUF model saved successfully\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nError saving GGUF model: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "441e95eb29c3473596c98e58f6760da9",
            "aa1c9329c79d49a2bafdad954938a557",
            "463f629064eb4c5e8be4763b1b21afca",
            "c47d42bb0f3b41dfb5f0fd4838607f93",
            "3a1add5822e24ff2b4da2d66fb5b6405",
            "39fd2e6640074ec289980a098cf18ef9",
            "aaaeeb47200b46daafb7eca0f29da806",
            "d6fa1f86ad424dce8d050c50784270c3",
            "accab2a3de994ac0b5363f289b186cdb",
            "eddfe7e33ed344c684929b203fdf009f",
            "1357bc9ca2cb473cb3d4487eb6336dcb",
            "cee19bb28c27470eb461ffe1eb09e47b",
            "0d5bc21145c848aea1862f0c2fa109f6",
            "61f06ebf781c413bbc43bbda50f97235",
            "4b0041b4902e424c9d706822cf15f113",
            "758d0819f45048399ecca711c1bd4ff6",
            "0b3d622627a54b11a1b2318606f0d054",
            "cfa79cf66f5e4a338bd65f127e2f44d0",
            "f2f3fc4a17af4273a3546b4d45ca87bb",
            "3cfb6c3e51824dfa913588cce4bdef46",
            "f2d59b8a58d346f180053f65933c18fe",
            "e79baaba734447f6a6bdd9fe16353353"
          ]
        },
        "id": "BWriLn7S_qx4",
        "outputId": "b2f60bcd-a3be-4a28-f33d-550d4a74803e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Colab environment...\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.4.3)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: xformers==0.0.29.post3 in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: trl==0.15.2 in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.11/dist-packages (2025.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (4.25.7)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Colab environment setup complete!\n",
            "Loading and preparing dataset...\n",
            "\n",
            "First few rows of the dataset:\n",
            "                            Child  \\\n",
            "0                          Child    \n",
            "1  I don’t want to visit Grandma!   \n",
            "2        My cousin is mean to me!   \n",
            "3           I don’t like my room!   \n",
            "4         I’m bored of this game!   \n",
            "\n",
            "                                               Robot  \n",
            "0                                             Robot   \n",
            "1  Visiting family can be fun! Let’s make it a ni...  \n",
            "2  That’s sad. Maybe we can talk to them and be f...  \n",
            "3  Maybe we can make your room more fun and cozy ...  \n",
            "4  That’s okay. We can think of another fun game ...  \n",
            "\n",
            "Successfully created 523 conversation pairs\n",
            "\n",
            "Starting model training...\n",
            "==((====))==  Unsloth 2025.4.3: Fast Gemma3 patching. Transformers: 4.51.3. vLLM: 0.8.5.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Unsloth: Making `model.base_model.model.language_model.model` require gradients\n",
            "\n",
            "Formatting dataset for training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/523 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "441e95eb29c3473596c98e58f6760da9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Switching to float32 training since model cannot work with float16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/523 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cee19bb28c27470eb461ffe1eb09e47b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 523 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 14,901,248/4,000,000,000 (0.37% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>12.719400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>12.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>12.533300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>11.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>9.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>7.978200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>5.872700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.521600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.417700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.878700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3.381700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3.039400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.964900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.561600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.254000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.880200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.440200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.375300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.506100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.351500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.332000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.290600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.115900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.319200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.126700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.942300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.889800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.939700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.793900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.746700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.965700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.898600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.858200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.700600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.758500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.838300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.914700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.925700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.760400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.814500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.738900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.743700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.801900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.905600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.927800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.781000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.720400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.788300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.022200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training completed in 176.9654 seconds\n",
            "Training completed in 2.95 minutes\n",
            "\n",
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "Peak reserved memory = 9.99 GB.\n",
            "Peak reserved memory % of max memory = 67.77 %.\n",
            "\n",
            "Saving model...\n",
            "Model saved successfully\n",
            "\n",
            "Testing model with sample inputs:\n",
            "\n",
            "Error during testing: name 'datetime' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDEvTWWC_rTk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "441e95eb29c3473596c98e58f6760da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa1c9329c79d49a2bafdad954938a557",
              "IPY_MODEL_463f629064eb4c5e8be4763b1b21afca",
              "IPY_MODEL_c47d42bb0f3b41dfb5f0fd4838607f93"
            ],
            "layout": "IPY_MODEL_3a1add5822e24ff2b4da2d66fb5b6405"
          }
        },
        "aa1c9329c79d49a2bafdad954938a557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fd2e6640074ec289980a098cf18ef9",
            "placeholder": "​",
            "style": "IPY_MODEL_aaaeeb47200b46daafb7eca0f29da806",
            "value": "Map: 100%"
          }
        },
        "463f629064eb4c5e8be4763b1b21afca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6fa1f86ad424dce8d050c50784270c3",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_accab2a3de994ac0b5363f289b186cdb",
            "value": 523
          }
        },
        "c47d42bb0f3b41dfb5f0fd4838607f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eddfe7e33ed344c684929b203fdf009f",
            "placeholder": "​",
            "style": "IPY_MODEL_1357bc9ca2cb473cb3d4487eb6336dcb",
            "value": " 523/523 [00:00&lt;00:00, 11434.04 examples/s]"
          }
        },
        "3a1add5822e24ff2b4da2d66fb5b6405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39fd2e6640074ec289980a098cf18ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaaeeb47200b46daafb7eca0f29da806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6fa1f86ad424dce8d050c50784270c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "accab2a3de994ac0b5363f289b186cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eddfe7e33ed344c684929b203fdf009f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1357bc9ca2cb473cb3d4487eb6336dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee19bb28c27470eb461ffe1eb09e47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d5bc21145c848aea1862f0c2fa109f6",
              "IPY_MODEL_61f06ebf781c413bbc43bbda50f97235",
              "IPY_MODEL_4b0041b4902e424c9d706822cf15f113"
            ],
            "layout": "IPY_MODEL_758d0819f45048399ecca711c1bd4ff6"
          }
        },
        "0d5bc21145c848aea1862f0c2fa109f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3d622627a54b11a1b2318606f0d054",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa79cf66f5e4a338bd65f127e2f44d0",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "61f06ebf781c413bbc43bbda50f97235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f3fc4a17af4273a3546b4d45ca87bb",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cfb6c3e51824dfa913588cce4bdef46",
            "value": 523
          }
        },
        "4b0041b4902e424c9d706822cf15f113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d59b8a58d346f180053f65933c18fe",
            "placeholder": "​",
            "style": "IPY_MODEL_e79baaba734447f6a6bdd9fe16353353",
            "value": " 523/523 [00:04&lt;00:00, 126.29 examples/s]"
          }
        },
        "758d0819f45048399ecca711c1bd4ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3d622627a54b11a1b2318606f0d054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa79cf66f5e4a338bd65f127e2f44d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2f3fc4a17af4273a3546b4d45ca87bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cfb6c3e51824dfa913588cce4bdef46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2d59b8a58d346f180053f65933c18fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79baaba734447f6a6bdd9fe16353353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}