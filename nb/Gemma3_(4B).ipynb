{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geeteshkamble/AI/blob/main/nb/Gemma3_(4B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from unsloth import FastModel\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from unsloth.chat_templates import get_chat_template, standardize_data_formats, train_on_responses_only\n",
        "from transformers import TextStreamer\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVpJtnXzXERU",
        "outputId": "99881fe1-3f33-4c5c-b16f-f070e5d1f815"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 04-30 06:37:30 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 04-30 06:37:30 [__init__.py:239] Automatically detected platform cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Available models for training\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "]"
      ],
      "metadata": {
        "id": "lzNXFj_CXGSb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_colab():\n",
        "    \"\"\"Setup Colab environment with required dependencies.\"\"\"\n",
        "    if \"COLAB_\" in \"\".join(os.environ.keys()):\n",
        "        print(\"Setting up Colab environment...\")\n",
        "        # Install dependencies\n",
        "        !pip install --no-deps unsloth vllm\n",
        "        !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "        !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "        # Handle vLLM requirements\n",
        "        f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "        with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "            file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "        !pip install -r vllm_requirements.txt\n",
        "\n",
        "        # Clear some modules to avoid conflicts\n",
        "        modules = list(sys.modules.keys())\n",
        "        for x in modules:\n",
        "            if \"PIL\" in x or \"google\" in x:\n",
        "                sys.modules.pop(x)\n",
        "\n",
        "        print(\"Colab environment setup complete!\")"
      ],
      "metadata": {
        "id": "RBak07mAXWt5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_dataset(csv_path):\n",
        "    \"\"\"Load and prepare the negative words dataset.\"\"\"\n",
        "    try:\n",
        "        # Read the CSV file with explicit column names\n",
        "        df = pd.read_csv(csv_path, encoding='utf-8', names=['Child', 'Robot'])\n",
        "\n",
        "        # Print first few rows for debugging\n",
        "        print(\"\\nFirst few rows of the dataset:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Create conversations format\n",
        "        conversations = []\n",
        "        for _, row in df.iterrows():\n",
        "            # Skip empty rows or header row\n",
        "            if pd.isna(row['Child']) or pd.isna(row['Robot']) or row['Child'] == 'Child':\n",
        "                continue\n",
        "\n",
        "            # Clean and validate the text\n",
        "            child_text = str(row['Child']).strip()\n",
        "            robot_text = str(row['Robot']).strip()\n",
        "\n",
        "            if child_text and robot_text:  # Only add if both texts are non-empty\n",
        "                conversation = [\n",
        "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": child_text}]},\n",
        "                    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": robot_text}]}\n",
        "                ]\n",
        "                conversations.append({\"conversations\": conversation})\n",
        "\n",
        "        if not conversations:\n",
        "            raise ValueError(\"No valid conversations found in the dataset\")\n",
        "\n",
        "        # Convert to HuggingFace dataset\n",
        "        dataset = Dataset.from_list(conversations)\n",
        "        print(f\"\\nSuccessfully created {len(conversations)} conversation pairs\")\n",
        "        return dataset\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"Error: The CSV file is empty\")\n",
        "        raise\n",
        "    except pd.errors.ParserError:\n",
        "        print(\"Error: The CSV file is not properly formatted\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {str(e)}\")\n",
        "        print(\"\\nPlease ensure your CSV file:\")\n",
        "        print(\"1. Has two columns (negative statement and positive response)\")\n",
        "        print(\"2. Is properly formatted with commas as separators\")\n",
        "        print(\"3. Contains valid text in both columns\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "APB-nfdzXYuY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(dataset, tokenizer):\n",
        "    \"\"\"Format the dataset using the chat template.\"\"\"\n",
        "    def formatting_prompts_func(examples):\n",
        "        convos = examples[\"conversations\"]\n",
        "        texts = []\n",
        "        for convo in convos:\n",
        "            # Format each conversation into a single text string\n",
        "            formatted_text = \"\"\n",
        "            for message in convo:\n",
        "                role = message[\"role\"]\n",
        "                content = message[\"content\"][0][\"text\"]\n",
        "                if role == \"user\":\n",
        "                    formatted_text += f\"<start_of_turn>user\\n{content}<end_of_turn>\\n\"\n",
        "                else:  # assistant\n",
        "                    formatted_text += f\"<start_of_turn>model\\n{content}<end_of_turn>\\n\"\n",
        "            texts.append(formatted_text)\n",
        "        return {\"text\": texts}\n",
        "\n",
        "    return dataset.map(formatting_prompts_func, batched=True)"
      ],
      "metadata": {
        "id": "OA6rIuKOXbgg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataset, model_name=\"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\", max_steps=60):\n",
        "    \"\"\"Train the Gemma-3 model on the dataset.\"\"\"\n",
        "    # Initialize model and tokenizer\n",
        "    model, tokenizer = FastModel.from_pretrained(\n",
        "        model_name=model_name,\n",
        "        max_seq_length=2048,  # Choose any for long context!\n",
        "        load_in_4bit=True,    # 4 bit quantization to reduce memory\n",
        "        load_in_8bit=False,   # A bit more accurate, uses 2x memory\n",
        "        full_finetuning=False, # We have full finetuning now!\n",
        "    )\n",
        "\n",
        "    # Get PEFT model\n",
        "    model = FastModel.get_peft_model(\n",
        "        model,\n",
        "        finetune_vision_layers=False,  # Turn off for just text!\n",
        "        finetune_language_layers=True,  # Should leave on!\n",
        "        finetune_attention_modules=True,  # Attention good for GRPO\n",
        "        finetune_mlp_modules=True,  # Should leave on always!\n",
        "        r=8,           # Larger = higher accuracy, but might overfit\n",
        "        lora_alpha=8,  # Recommended alpha == r at least\n",
        "        lora_dropout=0,\n",
        "        bias=\"none\",\n",
        "        random_state=3407,\n",
        "    )\n",
        "\n",
        "    # Format dataset\n",
        "    print(\"\\nFormatting dataset for training...\")\n",
        "    dataset = format_dataset(dataset, tokenizer)\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=dataset,\n",
        "        eval_dataset=None,\n",
        "        args=SFTConfig(\n",
        "            dataset_text_field=\"text\",\n",
        "            per_device_train_batch_size=2,\n",
        "            gradient_accumulation_steps=4,  # Use GA to mimic batch size!\n",
        "            warmup_steps=5,\n",
        "            max_steps=max_steps,\n",
        "            learning_rate=2e-4,  # Reduce to 2e-5 for long training runs\n",
        "            logging_steps=1,\n",
        "            optim=\"adamw_8bit\",\n",
        "            weight_decay=0.01,\n",
        "            lr_scheduler_type=\"linear\",\n",
        "            seed=3407,\n",
        "            report_to=\"none\",  # Use this for WandB etc\n",
        "            dataset_num_proc=2,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nStarting training...\")\n",
        "    trainer_stats = trainer.train()\n",
        "\n",
        "    return model, tokenizer, trainer_stats\n"
      ],
      "metadata": {
        "id": "9G4cFLF_Xdly"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, tokenizer, test_inputs):\n",
        "    \"\"\"Test the trained model with sample inputs.\"\"\"\n",
        "    results = []\n",
        "    for input_text in test_inputs:\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": input_text}]\n",
        "        }]\n",
        "\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "        )\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **tokenizer([text], return_tensors=\"pt\").to(\"cuda\"),\n",
        "            max_new_tokens=200,  # Increase for longer outputs!\n",
        "            temperature=1.0,    # Recommended Gemma-3 settings!\n",
        "            top_p=0.95,         # Recommended Gemma-3 settings!\n",
        "            top_k=64,           # Recommended Gemma-3 settings!\n",
        "        )\n",
        "\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        results.append({\"input\": input_text, \"response\": response})\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "BioIU0SFXpcJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Setup Colab environment if running in Colab\n",
        "    setup_colab()\n",
        "\n",
        "    # Load and prepare dataset\n",
        "    print(\"Loading and preparing dataset...\")\n",
        "    try:\n",
        "        dataset = load_and_prepare_dataset(\"Negative words.csv\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFailed to load dataset: {str(e)}\")\n",
        "        print(\"\\nPlease check your CSV file and try again.\")\n",
        "        return\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nStarting model training...\")\n",
        "    try:\n",
        "        model, tokenizer, trainer_stats = train_model(dataset)\n",
        "        print(f\"\\nTraining completed in {trainer_stats.metrics['train_runtime']} seconds\")\n",
        "        print(f\"Training completed in {round(trainer_stats.metrics['train_runtime']/60, 2)} minutes\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during training: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Show memory stats\n",
        "    try:\n",
        "        gpu_stats = torch.cuda.get_device_properties(0)\n",
        "        used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "        max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "        print(f\"\\nGPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "        print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "        print(f\"Peak reserved memory % of max memory = {round(used_memory / max_memory * 100, 3)} %.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError getting GPU stats: {str(e)}\")\n",
        "\n",
        "    # Save the model\n",
        "    print(\"\\nSaving model...\")\n",
        "    try:\n",
        "        model.save_pretrained(\"gemma-3-negative-words\")\n",
        "        tokenizer.save_pretrained(\"gemma-3-negative-words\")\n",
        "        print(\"Model saved successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError saving model: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Test cases\n",
        "    test_inputs = [\n",
        "        # \"I don't want to do my homework!\",\n",
        "        # \"I don't like vegetables!\",\n",
        "        # \"I don't want to go to school today!\",\n",
        "        # \"I don't want to share my toys!\",\n",
        "        # \"I don't want to go to bed!\",\n",
        "        # \"I don't want to clean my room!\",\n",
        "        # \"I don't want to help with dinner!\",\n",
        "        # \"I don't want to play outside!\",\n",
        "        # \"I don't want to take a bath!\",\n",
        "        # \"I don't want to exercise!\"\n",
        "        #\"i wanted to buy a house by doing harwork\"\n",
        "        #\"I eated all the cookies so now the dog is guilty.\"\n",
        "        \"I eat a chewing gum and stuck it under my school bench\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTesting model with sample inputs:\")\n",
        "    try:\n",
        "        results = test_model(model, tokenizer, test_inputs)\n",
        "\n",
        "        for result in results:\n",
        "            print(f\"\\nInput: {result['input']}\")\n",
        "            print(f\"Response: {result['response']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during testing: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # # Save to float16 for deployment\n",
        "    # print(\"\\nSaving model in float16 format for deployment...\")\n",
        "    # try:\n",
        "    #     model.save_pretrained_merged(\"gemma-3-negative-words-float16\", tokenizer)\n",
        "    #     print(\"Float16 model saved successfully\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nError saving float16 model: {str(e)}\")\n",
        "\n",
        "    # # Save to GGUF format\n",
        "    # print(\"\\nSaving model in GGUF format...\")\n",
        "    # try:\n",
        "    #     model.save_pretrained_gguf(\n",
        "    #         \"gemma-3-negative-words-gguf\",\n",
        "    #         quantization_type=\"Q8_0\",  # For now only Q8_0, BF16, F16 supported\n",
        "    #     )\n",
        "    #     print(\"GGUF model saved successfully\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nError saving GGUF model: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a68bcc652074243bf1983306b9a0a70",
            "4e4f2446db7147978718d06863c2e2e4",
            "3b259521b7d34ba7b7c27d4f8069168c",
            "9d8e99549c074012bab4172737455c29",
            "0963e4a8a80a44678c697a3f36ee0ff6",
            "0edf4265f68946148a8a2a4931b2e800",
            "5cd3890f7d064d6f91dc90613f120c85",
            "bed30b74ade34c039fa70b3ab673b529",
            "a09a27beea10487ebad41f9cc04cd002",
            "8b945e4dd29e4e3a946d62759c5604f8",
            "8d665918d5564cb4971f132598cac8c8",
            "0deaf2fe9fd64f649a24358a4cc51b74",
            "f9fd0c9ebf5e4eb1bcfafc12d974aec6",
            "ee79d39cac234bff879e3d44e52a29a1",
            "f738ae58e9b743d59cf6eb02fec9e1ba",
            "3283bd34c1304b27a1f78f7a3b8609f8",
            "57f09b4392e04dfcb3dd150ff174dbd5",
            "a90b0fbb9c0b4f8da0cdce26477e7994",
            "91dec2ca7eac4d46a2f49b9a13eaf2ec",
            "32ba44427bc84df29e7203b8db4f679c",
            "7454511c2f3f4bc1aba628471b843d38",
            "846b6ac7cddd4a8c98bbf5cf4e9b83db"
          ]
        },
        "id": "rUzuXVH6dVad",
        "outputId": "1122c00f-83d7-471b-ac5d-19362b8fadee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Colab environment...\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.4.3)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: xformers==0.0.29.post3 in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: trl==0.15.2 in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.11/dist-packages (2025.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (4.25.7)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Ignoring six: markers 'python_version > \"3.11\"' don't match your environment\n",
            "Ignoring setuptools: markers 'python_version > \"3.11\"' don't match your environment\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 1)) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 7)) (1.0.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 8)) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->-r vllm_requirements.txt (line 9)) (0.30.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 10)) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 11)) (4.25.7)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.115.12)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 13)) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 14)) (1.76.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 15)) (2.11.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 16)) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 17)) (11.2.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 18)) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 19)) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 20)) (0.10.11)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 21)) (0.7.19)\n",
            "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 22)) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 23)) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.18 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 24)) (0.1.18)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 25)) (4.13.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 26)) (3.18.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 27)) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 28)) (26.4.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 29)) (0.19.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 30)) (0.16.2)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 31)) (8.0.0)\n",
            "Requirement already satisfied: mistral_common>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.4->-r vllm_requirements.txt (line 32)) (1.5.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 33)) (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 34)) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 37)) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.3 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 38)) (0.9.3)\n",
            "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 39)) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 40)) (3.1.1)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 41)) (1.0.5)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 42)) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 43)) (1.15.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 44)) (1.11.1.4)\n",
            "Requirement already satisfied: opentelemetry-sdk<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 45)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-api<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 46)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 47)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r vllm_requirements.txt (line 48)) (0.4.3)\n",
            "Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (5.6.3)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (4.23.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (20250224)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (2.6.0+cu124)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->-r vllm_requirements.txt (line 22)) (0.1.26)\n",
            "Requirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from xgrammar==0.1.18->-r vllm_requirements.txt (line 24)) (4.51.3)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from xgrammar==0.1.18->-r vllm_requirements.txt (line 24)) (3.2.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->-r vllm_requirements.txt (line 39)) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->-r vllm_requirements.txt (line 39)) (0.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r vllm_requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r vllm_requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r vllm_requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r vllm_requirements.txt (line 5)) (2025.1.31)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->-r vllm_requirements.txt (line 9)) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->-r vllm_requirements.txt (line 9)) (24.2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.46.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r vllm_requirements.txt (line 13)) (1.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->-r vllm_requirements.txt (line 14)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->-r vllm_requirements.txt (line 14)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->-r vllm_requirements.txt (line 14)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->-r vllm_requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->-r vllm_requirements.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->-r vllm_requirements.txt (line 15)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->-r vllm_requirements.txt (line 15)) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->-r vllm_requirements.txt (line 15)) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->-r vllm_requirements.txt (line 19)) (2024.11.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->-r vllm_requirements.txt (line 31)) (3.21.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 45)) (0.47b0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 46)) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 47)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 47)) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 47)) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 47)) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 47)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 47)) (1.26.0)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.0.7)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (2.2.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.34.2)\n",
            "Requirement already satisfied: hf-xet>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->-r vllm_requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->-r vllm_requirements.txt (line 46)) (1.17.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.15.2)\n",
            "Requirement already satisfied: rich-toolkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.14.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.0->-r vllm_requirements.txt (line 14)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.52.0->-r vllm_requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (0.24.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->outlines==0.1.11->-r vllm_requirements.txt (line 22)) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.0->xgrammar==0.1.18->-r vllm_requirements.txt (line 24)) (0.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (8.1.8)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (15.0.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->-r vllm_requirements.txt (line 12)) (0.1.2)\n",
            "Colab environment setup complete!\n",
            "Loading and preparing dataset...\n",
            "\n",
            "First few rows of the dataset:\n",
            "                            Child  \\\n",
            "0                          Child    \n",
            "1  I donâ€™t want to visit Grandma!   \n",
            "2        My cousin is mean to me!   \n",
            "3           I donâ€™t like my room!   \n",
            "4         Iâ€™m bored of this game!   \n",
            "\n",
            "                                               Robot  \n",
            "0                                             Robot   \n",
            "1  Visiting family can be fun! Letâ€™s make it a ni...  \n",
            "2  Thatâ€™s sad. Maybe we can talk to them and be f...  \n",
            "3  Maybe we can make your room more fun and cozy ...  \n",
            "4  Thatâ€™s okay. We can think of another fun game ...  \n",
            "\n",
            "Successfully created 523 conversation pairs\n",
            "\n",
            "Starting model training...\n",
            "==((====))==  Unsloth 2025.4.3: Fast Gemma3 patching. Transformers: 4.51.3. vLLM: 0.8.5.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Unsloth: Making `model.base_model.model.language_model.model` require gradients\n",
            "\n",
            "Formatting dataset for training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/523 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a68bcc652074243bf1983306b9a0a70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Switching to float32 training since model cannot work with float16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/523 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0deaf2fe9fd64f649a24358a4cc51b74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 523 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 14,901,248/4,000,000,000 (0.37% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 03:07, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>12.719400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>12.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>12.532900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>11.456500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>9.993700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>7.975500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>5.873300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.521100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.417100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.878000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.964700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.253500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.879500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.440200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.375400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.579600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.505800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.351300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.115800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.319000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.126400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.942300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.889500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.939500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.794100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.746800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.965600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.898500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.858100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.700600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.758600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.838200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.914500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.925500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.760700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.814500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.738700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.802000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.905400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.927700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.780900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.720300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.788200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.022300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training completed in 191.0776 seconds\n",
            "Training completed in 3.18 minutes\n",
            "\n",
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "Peak reserved memory = 9.982 GB.\n",
            "Peak reserved memory % of max memory = 67.716 %.\n",
            "\n",
            "Saving model...\n",
            "Model saved successfully\n",
            "\n",
            "Testing model with sample inputs:\n",
            "\n",
            "Input: I eated all the cookies so now the dog is guilty.\n",
            "Response: <bos><start_of_turn>user\n",
            "I eated all the cookies so now the dog is guilty.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The dog is feeling bad and not sleeping.<end_of_turn>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Test cases\n",
        "    test_inputs = [\n",
        "        # \"I don't want to do my homework!\",\n",
        "        # \"I don't like vegetables!\",\n",
        "        # \"I don't want to go to school today!\",\n",
        "        # \"I don't want to share my toys!\",\n",
        "        # \"I don't want to go to bed!\",\n",
        "        # \"I don't want to clean my room!\",\n",
        "        # \"I don't want to help with dinner!\",\n",
        "        # \"I don't want to play outside!\",\n",
        "        # \"I don't want to take a bath!\",\n",
        "        # \"I don't want to exercise!\"\n",
        "        #\"i wanted to buy a house by doing harwork\"\n",
        "        \"I eated all the cookies so now the dog is guilty.\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTesting model with sample inputs:\")\n",
        "    try:\n",
        "        results = test_model(model, tokenizer, test_inputs)\n",
        "\n",
        "        for result in results:\n",
        "            print(f\"\\nInput: {result['input']}\")\n",
        "            print(f\"Response: {result['response']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during testing: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # # Save to float16 for deployment\n",
        "    # print(\"\\nSaving model in float16 format for deployment...\")\n",
        "    # try:\n",
        "    #     model.save_pretrained_merged(\"gemma-3-negative-words-float16\", tokenizer)\n",
        "    #     print(\"Float16 model saved successfully\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nError saving float16 model: {str(e)}\")\n",
        "\n",
        "    # # Save to GGUF format\n",
        "    # print(\"\\nSaving model in GGUF format...\")\n",
        "    # try:\n",
        "    #     model.save_pretrained_gguf(\n",
        "    #         \"gemma-3-negative-words-gguf\",\n",
        "    #         quantization_type=\"Q8_0\",  # For now only Q8_0, BF16, F16 supported\n",
        "    #     )\n",
        "    #     print(\"GGUF model saved successfully\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nError saving GGUF model: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "S6c7O7L6dbet"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a68bcc652074243bf1983306b9a0a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e4f2446db7147978718d06863c2e2e4",
              "IPY_MODEL_3b259521b7d34ba7b7c27d4f8069168c",
              "IPY_MODEL_9d8e99549c074012bab4172737455c29"
            ],
            "layout": "IPY_MODEL_0963e4a8a80a44678c697a3f36ee0ff6"
          }
        },
        "4e4f2446db7147978718d06863c2e2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0edf4265f68946148a8a2a4931b2e800",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5cd3890f7d064d6f91dc90613f120c85",
            "value": "Map:â€‡100%"
          }
        },
        "3b259521b7d34ba7b7c27d4f8069168c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed30b74ade34c039fa70b3ab673b529",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a09a27beea10487ebad41f9cc04cd002",
            "value": 523
          }
        },
        "9d8e99549c074012bab4172737455c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b945e4dd29e4e3a946d62759c5604f8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8d665918d5564cb4971f132598cac8c8",
            "value": "â€‡523/523â€‡[00:00&lt;00:00,â€‡10028.30â€‡examples/s]"
          }
        },
        "0963e4a8a80a44678c697a3f36ee0ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edf4265f68946148a8a2a4931b2e800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd3890f7d064d6f91dc90613f120c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed30b74ade34c039fa70b3ab673b529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09a27beea10487ebad41f9cc04cd002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b945e4dd29e4e3a946d62759c5604f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d665918d5564cb4971f132598cac8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0deaf2fe9fd64f649a24358a4cc51b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9fd0c9ebf5e4eb1bcfafc12d974aec6",
              "IPY_MODEL_ee79d39cac234bff879e3d44e52a29a1",
              "IPY_MODEL_f738ae58e9b743d59cf6eb02fec9e1ba"
            ],
            "layout": "IPY_MODEL_3283bd34c1304b27a1f78f7a3b8609f8"
          }
        },
        "f9fd0c9ebf5e4eb1bcfafc12d974aec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f09b4392e04dfcb3dd150ff174dbd5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a90b0fbb9c0b4f8da0cdce26477e7994",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=2):â€‡100%"
          }
        },
        "ee79d39cac234bff879e3d44e52a29a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91dec2ca7eac4d46a2f49b9a13eaf2ec",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32ba44427bc84df29e7203b8db4f679c",
            "value": 523
          }
        },
        "f738ae58e9b743d59cf6eb02fec9e1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7454511c2f3f4bc1aba628471b843d38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_846b6ac7cddd4a8c98bbf5cf4e9b83db",
            "value": "â€‡523/523â€‡[00:04&lt;00:00,â€‡131.25â€‡examples/s]"
          }
        },
        "3283bd34c1304b27a1f78f7a3b8609f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f09b4392e04dfcb3dd150ff174dbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90b0fbb9c0b4f8da0cdce26477e7994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91dec2ca7eac4d46a2f49b9a13eaf2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ba44427bc84df29e7203b8db4f679c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7454511c2f3f4bc1aba628471b843d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "846b6ac7cddd4a8c98bbf5cf4e9b83db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}